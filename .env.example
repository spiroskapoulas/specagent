# =============================================================================
# 3GPP SpecAgent Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# =============================================================================

# -----------------------------------------------------------------------------
# API Keys
# -----------------------------------------------------------------------------
# HuggingFace API key - REQUIRED when USE_LOCAL_LLM=false (for LLM inference)
# Get your free key at: https://huggingface.co/settings/tokens
HF_API_KEY=your-huggingface-api-key

# -----------------------------------------------------------------------------
# LLM Configuration
# -----------------------------------------------------------------------------
# Toggle between HuggingFace Inference API or local GGUF model
USE_LOCAL_LLM=false

# HuggingFace Inference API (when USE_LOCAL_LLM=false)
# Free tier models: Qwen/Qwen2.5-3B-Instruct, Qwen/Qwen2.5-1.5B-Instruct
LLM_MODEL=Qwen/Qwen2.5-3B-Instruct

# Local GGUF model (when USE_LOCAL_LLM=true)
# Download from: https://huggingface.co/Qwen/Qwen2.5-3B-Instruct-GGUF
LLM_MODEL_PATH=/models/qwen2.5-3b-instruct-q4_k_m.gguf
LLM_MODEL_NAME=qwen2.5-3b-instruct

# LLM settings (apply to both modes)
LLM_N_CTX=4096
LLM_N_GPU_LAYERS=0
LLM_TEMPERATURE=0.1
LLM_MAX_TOKENS=1024

# -----------------------------------------------------------------------------
# Embedding Configuration
# -----------------------------------------------------------------------------
# Use local sentence-transformers (recommended, no API needed)
USE_LOCAL_EMBEDDINGS=true

# Sentence transformer model
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# -----------------------------------------------------------------------------
# Chunking Configuration
# -----------------------------------------------------------------------------
# Target chunk size in tokens
CHUNK_SIZE=512

# Overlap between consecutive chunks
CHUNK_OVERLAP=64

# -----------------------------------------------------------------------------
# Retrieval Configuration
# -----------------------------------------------------------------------------
# Path to FAISS index file
FAISS_INDEX_PATH=data/index/faiss.index

# Path to chunk metadata JSON
METADATA_PATH=data/index/metadata.json

# Number of chunks to retrieve
RETRIEVAL_TOP_K=10

# Minimum similarity score (0.0-1.0)
SIMILARITY_THRESHOLD=0.3

# -----------------------------------------------------------------------------
# Agent Configuration
# -----------------------------------------------------------------------------
# Maximum query rewrite attempts
MAX_REWRITES=2

# Minimum confidence to skip rewriting (0.0-1.0)
GRADER_CONFIDENCE_THRESHOLD=0.6

# -----------------------------------------------------------------------------
# API Configuration
# -----------------------------------------------------------------------------
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=1

# -----------------------------------------------------------------------------
# Observability
# -----------------------------------------------------------------------------
# Logging level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Phoenix tracing endpoint
PHOENIX_ENDPOINT=http://localhost:6006

# Enable OpenTelemetry tracing
ENABLE_TRACING=true

# -----------------------------------------------------------------------------
# Data Paths
# -----------------------------------------------------------------------------
DATA_DIR=data
RAW_DATA_DIR=data/raw
PROCESSED_DATA_DIR=data/processed
